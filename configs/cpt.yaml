# @package _global_
defaults:
  - dataset: cpt_dataset
  - architecture: cpt_architecture
  - architecture/model: huggingface_model
  - tuner: cpt_tuner
  - logger: wandb
  - hydra: hydra
  - callbacks: callbacks
  - trainer: trainer

package_name: llm-fine-tune
project_dir: ${oc.env:PROJECT_DIR}/${package_name}
connected_dir: ${oc.env:CONNECTED_DIR}/${package_name}

seed: 2025

data_type: structural

split:
  train: train
  val: val
  test: test
  predict: predict

batch_size: 16
eval_batch_size: 16
workers_ratio: 8
use_all_workers: false

split_ratio: 1e-2
is_strict_split: false

dataset_name: open-Korean
dataset_format: parquet
is_sft: true
is_preprocessed: false
instruction_column_name: instruction
data_column_name: input
target_column_name: response
conversation_column_name: messages
role_column_name: role
content_column_name: content
assistant_column_name: assistant
upload_user: Qwen
model_type: Qwen3-8B
pretrained_model_name: ${upload_user}/${model_type}
custom_data_encoder_path: ${connected_dir}/merged/data_encoders/${pretrained_model_name}
revision: main
reference_data_encoder_name: Qwen/Qwen3-8B
left_padding: false
is_enable_thinking: false
merged_model_path: ${connected_dir}/merged/models/${pretrained_model_name}
data_max_length: 2048
target_max_length: 2048
target_min_length: 16
response_start_template: <|im_start|>${assistant_column_name}

quantization_type: origin
quantization_config:
  load_in_4bit: true
  bnb_4bit_quant_type: nf4
  bnb_4bit_use_double_quant: true
  bnb_4bit_compute_dtype: bfloat16
peft_type: origin
peft_config:
  r: 32
  lora_alpha: 64
  target_modules: all-linear
  lora_dropout: 0.1
  bias: none
  task_type: CAUSAL_LM
  inference_mode: false

lr: 5e-6
weight_decay: 1e-1
warmup_ratio: 5e-2
eta_min_ratio: 1e-2
interval: step
options:
  return_dict_in_generate: true
  output_scores: true

monitor: val_loss
tracking_direction: min

early_stop: false
patience: 2
min_delta: 0

devices: ${oc.decode:${oc.env:DEVICES}}
accelerator: gpu
strategy: deepspeed_stage_3_offload
log_every_n_steps: 10
precision: bf16
accumulate_grad_batches: 1
gradient_clip_val: 1
gradient_clip_algorithm: norm
epoch: 2
step: 250

model_name: CausalLM-CPT
mode: train

is_tuned: untuned
num_trials: 3
hparams_save_path: ${connected_dir}/hparams/${model_name}/${dataset_name}/${num_trials}_trials
tuned_hparams_path: ${hparams_save_path}/best_params.json

project_name: ${model_name}-${dataset_name}-${mode}
peft_info: quantization_type=${quantization_type}-peft_type=${peft_type}
peft_detail: r=${peft_config.r}-a=${peft_config.lora_alpha}
length_info: data_max_length=${data_max_length}-target_max_length=${target_max_length}
total_batch_size: bs=${batch_size}x${devices}x${accumulate_grad_batches}
save_detail: ${upload_user}_${model_type}-is_sft=${is_sft}-${peft_info}-${peft_detail}-${length_info}-precision=${precision}-${total_batch_size}
convert_at_end: false
resumed_step: 0
ckpt_path: ${callbacks.model_checkpoint.dirpath}/step=${step}.ckpt

submission_file_name: test
per_device_save_path: ${connected_dir}/sharded_results/${save_detail}-step=${step}
logit_name: ${save_detail}-step=${step}
pred_name: ${save_detail}-step=${step}
submission_name: ${save_detail}-step=${step}

user_name: ${oc.env:USER_NAME}
model_detail: Qwen3-8B
upload_tag: open-Korean
num_safetensors: 10

korean_model_name: beomi/OPEN-SOLAR-KO-10.7B
reasoning_model_name: Qwen/QwQ-32B
reasoning_tokens:
  - <think>
  - </think>

run_name: ${project_name}
work_dir: ${hydra:runtime.cwd}